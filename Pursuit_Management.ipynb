{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avNRWco88XkY",
        "outputId": "5c426836-603c-49a9-8bee-f5a0c29db3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skill Match Scores:\n",
            "[[ 0.56842995  0.05028136  0.22813097]\n",
            " [-0.02065979  0.37222812  0.02823429]\n",
            " [ 0.12831999  0.11330611  0.75485259]]\n",
            "\n",
            "Final Task Assignments:\n",
            "Alice -> Task 1\n",
            "Bob -> Task 2\n",
            "Charlie -> Task 3\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "employees = [\n",
        "    {\"name\": \"Alice\", \"skills\": \"Python, Machine Learning\", \"availability\": \"2025-01-01 to 2025-01-20\"},\n",
        "    {\"name\": \"Bob\", \"skills\": \"Java, Spring Boot\", \"availability\": \"2025-01-10 to 2025-01-25\"},\n",
        "    {\"name\": \"Charlie\", \"skills\": \"C++, Data Analysis\", \"availability\": \"2025-01-05 to 2025-01-15\"}\n",
        "]\n",
        "\n",
        "tasks = [\n",
        "    {\"name\": \"Task 1\", \"description\": \"Develop a Python-based ML model, Apply NLP\", \"deadline\": \"2025-01-15\"},\n",
        "    {\"name\": \"Task 2\", \"description\": \"Create a Java backend system. Write a Program to Find Factorial of a Number in Java\", \"deadline\": \"2025-01-20\"},\n",
        "    {\"name\": \"Task 3\", \"description\": \"Analyze data for trends using C++\", \"deadline\": \"2025-01-12\"}\n",
        "]\n",
        "\n",
        "def match_tasks_to_employees(tasks, employees):\n",
        "    task_embeddings = [model.encode(task['description'], convert_to_tensor=True) for task in tasks]\n",
        "    employee_scores = []\n",
        "\n",
        "    for emp in employees:\n",
        "        emp_embedding = model.encode(emp['skills'], convert_to_tensor=True)\n",
        "        scores = []\n",
        "\n",
        "        for task_embedding in task_embeddings:\n",
        "            similarity_score = util.cos_sim(emp_embedding, task_embedding).item()\n",
        "            scores.append(similarity_score)\n",
        "\n",
        "        employee_scores.append(scores)\n",
        "\n",
        "    return np.array(employee_scores)\n",
        "\n",
        "score_matrix = match_tasks_to_employees(tasks, employees)\n",
        "\n",
        "print(\"Skill Match Scores:\")\n",
        "print(score_matrix)\n",
        "\n",
        "num_employees = len(employees)\n",
        "num_tasks = len(tasks)\n",
        "\n",
        "q_table = np.zeros((num_employees, num_tasks))\n",
        "\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "episodes = 1000\n",
        "\n",
        "tasks_assigned = [False] * num_tasks\n",
        "employees_assigned = [False] * num_employees\n",
        "\n",
        "def reward(employee_idx, task_idx):\n",
        "    if employees_assigned[employee_idx] or tasks_assigned[task_idx]:\n",
        "        return -10\n",
        "\n",
        "    skill_match = score_matrix[employee_idx][task_idx]\n",
        "    return 10 * skill_match\n",
        "\n",
        "for episode in range(episodes):\n",
        "    tasks_assigned = [False] * num_tasks\n",
        "    employees_assigned = [False] * num_employees\n",
        "\n",
        "    for _ in range(min(num_employees, num_tasks)):\n",
        "        employee_idx = random.randint(0, num_employees - 1)\n",
        "        if employees_assigned[employee_idx]:\n",
        "            continue\n",
        "\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            task_idx = random.randint(0, num_tasks - 1)\n",
        "        else:\n",
        "            task_idx = np.argmax(q_table[employee_idx])\n",
        "\n",
        "        if tasks_assigned[task_idx]:\n",
        "            continue\n",
        "\n",
        "        r = reward(employee_idx, task_idx)\n",
        "\n",
        "        q_table[employee_idx, task_idx] = q_table[employee_idx, task_idx] + alpha * (\n",
        "            r + gamma * np.max(q_table[employee_idx]) - q_table[employee_idx, task_idx]\n",
        "        )\n",
        "\n",
        "        tasks_assigned[task_idx] = True\n",
        "        employees_assigned[employee_idx] = True\n",
        "\n",
        "final_assignments = {}\n",
        "tasks_assigned = [False] * num_tasks\n",
        "employees_assigned = [False] * num_employees\n",
        "\n",
        "for emp_idx in range(num_employees):\n",
        "    best_task_idx = np.argmax(q_table[emp_idx])\n",
        "\n",
        "    if not tasks_assigned[best_task_idx] and not employees_assigned[emp_idx]:\n",
        "        final_assignments[employees[emp_idx]['name']] = tasks[best_task_idx]['name']\n",
        "        tasks_assigned[best_task_idx] = True\n",
        "        employees_assigned[emp_idx] = True\n",
        "\n",
        "print(\"\\nFinal Task Assignments:\")\n",
        "for emp, task in final_assignments.items():\n",
        "    print(f\"{emp} -> {task}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "num_employees = len(employees)\n",
        "num_tasks = len(tasks)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for emp_idx in range(num_employees):\n",
        "    for task_idx in range(num_tasks):\n",
        "        skill_match = score_matrix[emp_idx][task_idx]\n",
        "        complexity = random.uniform(0.4, 0.9)\n",
        "        X_train.append([complexity, skill_match])\n",
        "        y_train.append(random.randint(1, 15))\n",
        "\n",
        "completion_model = LinearRegression()\n",
        "completion_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nTask Completion Predictions:\")\n",
        "for task, scores in zip(tasks, score_matrix):\n",
        "    avg_skill_match = np.mean(scores)\n",
        "    complexity = random.uniform(0.4, 0.9)\n",
        "    predicted_days = completion_model.predict([[complexity, avg_skill_match]])[0]\n",
        "    task[\"predicted_completion_days\"] = predicted_days\n",
        "    print(f\"{task['name']} -> Predicted Completion Days: {predicted_days:.2f}, Deadline: {task['deadline']}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5OOZsZ18Y2u",
        "outputId": "c45ba782-e7e7-4a13-af35-079445bdf766"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task Completion Predictions:\n",
            "Task 1 -> Predicted Completion Days: 7.20, Deadline: 2025-01-15\n",
            "Task 2 -> Predicted Completion Days: 8.44, Deadline: 2025-01-20\n",
            "Task 3 -> Predicted Completion Days: 8.39, Deadline: 2025-01-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for task, scores in zip(tasks, score_matrix):\n",
        "    avg_skill_match = np.mean(scores)\n",
        "    complexity = random.uniform(0.4, 0.9)\n",
        "    predicted_days = completion_model.predict([[complexity, avg_skill_match]])[0]\n",
        "    task[\"predicted_completion_days\"] = predicted_days\n",
        "    print(f\"{task['name']} -> Predicted Completion Days: {predicted_days:.2f}, Deadline: {task['deadline']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVQhzVrum3-a",
        "outputId": "bc4b03be-a13c-4830-9a3b-eada0edab40d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 -> Predicted Completion Days: 8.81, Deadline: 2025-01-15\n",
            "Task 2 -> Predicted Completion Days: 9.39, Deadline: 2025-01-20\n",
            "Task 3 -> Predicted Completion Days: 7.37, Deadline: 2025-01-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def notify_about_delays(tasks):\n",
        "    today = datetime.now()\n",
        "\n",
        "    for task in tasks:\n",
        "        if \"predicted_completion_days\" not in task or task[\"predicted_completion_days\"] is None:\n",
        "            print(f\"⚠️ {task['name']} is missing predicted completion days. Please check.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            deadline_date = datetime.strptime(task[\"deadline\"], \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            print(f\"⚠️ The deadline format for {task['name']} seems incorrect. It should be YYYY-MM-DD.\")\n",
        "            continue\n",
        "\n",
        "        days_left = (deadline_date - today).days\n",
        "        predicted_days = task[\"predicted_completion_days\"]\n",
        "\n",
        "        print(f\"{task['name']} - Days Left: {days_left}, Predicted Completion Days: {predicted_days:.2f}\")\n",
        "\n",
        "        if days_left < predicted_days:\n",
        "            print(f\"⚠️ {task['name']} is falling behind. You might need to reassign resources or adjust timelines.\")\n",
        "        elif days_left <= 3:\n",
        "            print(f\"⚠️ {task['name']} is almost due! Only {days_left} days left to complete.\")\n",
        "\n",
        "# Execute the function\n",
        "notify_about_delays(tasks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0KEwLiy8dT9",
        "outputId": "01a841ed-99c2-47d8-a5d8-4241d05c490d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 - Days Left: 26, Predicted Completion Days: 8.81\n",
            "Task 2 - Days Left: 31, Predicted Completion Days: 9.39\n",
            "Task 3 - Days Left: 23, Predicted Completion Days: 7.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \api\n",
        "\n",
        "def generate_summaries(tasks):\n",
        "    print(\"\\nAI-Generated Task Summaries:\")\n",
        "    for task in tasks:\n",
        "        description = task.get('description', '')\n",
        "\n",
        "        prompt = (\n",
        "            f\"Write a concise and clear summary for the task named '{task['name']}' \"\n",
        "            f\"with the deadline '{task['deadline']}'. The task description is: {description}.\"\n",
        "        )\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=100,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        summary = response.choices[0].message.content.strip()\n",
        "        print(f\"{task['name']} -> {summary} -> {['deadline']}\")\n",
        "\n",
        "\n",
        "# Generate summaries\n",
        "generate_summaries(tasks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-oV8-I08hY7",
        "outputId": "89998da8-225e-4543-8ada-7df62e866bb2"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AI-Generated Task Summaries:\n",
            "Task 1 -> Task 1: Develop a Python-based ML model utilizing NLP techniques. Deadline: 2025-01-15. -> ['deadline']\n",
            "Task 2 -> Summary:\n",
            "Task 2 involves creating a Java backend system by the deadline of January 20, 2025. -> ['deadline']\n",
            "Task 3 -> Task 3 requires analyzing data for trends using C++ by the deadline of January 12, 2025. -> ['deadline']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnEmVWWp04Gy",
        "outputId": "ea1a575b-00f0-4082-e78e-d05ae26a6f4a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhJ7SVhX1MnC",
        "outputId": "87aca3ab-ddd1-40a5-bbb0-516e1aede092"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.12)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.12->langchain_community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.12->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.12 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Write a concise and clear summary for the task named '{task_name}' with the deadline '{deadline}'. The task description is: {task_description}.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"task_name\", \"deadline\", \"task_description\"], template=prompt_template)\n",
        "\n",
        "summary_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "def generate_summaries(tasks):\n",
        "    print(\"\\nAI-Generated Task Summaries:\")\n",
        "    for task in tasks:\n",
        "        task_name = task['name']\n",
        "        deadline = task['deadline']\n",
        "        task_description = task.get('description', '')\n",
        "\n",
        "        summary = summary_chain.run(task_name=task_name, deadline=deadline, task_description=task_description)\n",
        "\n",
        "        print(f\"{task['name']} -> {summary} -> Deadline: {task['deadline']}\")\n",
        "\n",
        "\n",
        "# Generate summaries\n",
        "generate_summaries(tasks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSJit9AJ0RS1",
        "outputId": "f4b99583-e01a-43c8-e5b6-c85572a83b94"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AI-Generated Task Summaries:\n",
            "Task 1 -> Summary:\n",
            "Task 1 involves developing a Python-based ML model and applying NLP techniques. The deadline for this task is January 15, 2025. -> Deadline: 2025-01-15\n",
            "Task 2 -> Task 2: Create a Java backend system to write a program that finds the factorial of a number. Deadline is 2025-01-20. -> Deadline: 2025-01-20\n",
            "Task 3 -> Task 3 involves analyzing data for trends using C++. The deadline for this task is January 12, 2025. -> Deadline: 2025-01-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the learned Q-table\n",
        "print(\"\\nLearned Q-Table:\")\n",
        "for state in range(q_table.shape[0]):\n",
        "    print(f\"State: {state}\")\n",
        "    for action in range(q_table.shape[1]):\n",
        "        q_value = q_table[state, action]\n",
        "        print(f\"  Action {action}: Q-Value = {q_value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_No7eWae9A9v",
        "outputId": "176f26fc-0f07-4342-e7dc-de1f99ce57be"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Learned Q-Table:\n",
            "State: 0\n",
            "  Action 0: Q-Value = 14.21\n",
            "  Action 1: Q-Value = 7.41\n",
            "  Action 2: Q-Value = 6.29\n",
            "State: 1\n",
            "  Action 0: Q-Value = 5.70\n",
            "  Action 1: Q-Value = 11.79\n",
            "  Action 2: Q-Value = 5.66\n",
            "State: 2\n",
            "  Action 0: Q-Value = 10.40\n",
            "  Action 1: Q-Value = 9.88\n",
            "  Action 2: Q-Value = 18.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_win_probability(employee, task):\n",
        "    skill_match = score_matrix[employee][task]\n",
        "    complexity = tasks[task].get(\"complexity\", 0.5)\n",
        "    days_to_complete = tasks[task][\"predicted_completion_days\"]\n",
        "    days_left = days_until_deadline(tasks[task][\"deadline\"])\n",
        "    urgency_factor = max(0, (days_left - days_to_complete) / max(1, days_left))\n",
        "\n",
        "    win_prob = 0.5 * skill_match + 0.3 * urgency_factor - 0.2 * complexity\n",
        "    return max(0, min(1, win_prob))\n",
        "\n",
        "\n",
        "def reward(employee_assigned, task_assigned):\n",
        "    if employees_assigned[employee_assigned]:\n",
        "        return -10\n",
        "    if tasks_assigned[task_assigned]:\n",
        "        return -10\n",
        "\n",
        "    skill_match = score_matrix[employee_assigned][task_assigned]\n",
        "    task = tasks[task_assigned]\n",
        "    days_to_complete = task.get(\"predicted_completion_days\", 10)\n",
        "    deadline = days_until_deadline(task[\"deadline\"])\n",
        "    urgency_factor = max(0, (deadline - days_to_complete) / max(1, deadline))\n",
        "\n",
        "    win_prob = calculate_win_probability(employee_assigned, task_assigned)\n",
        "\n",
        "    return 10 * skill_match + 5 * urgency_factor + 20 * win_prob\n",
        "\n",
        "def prioritize_tasks():\n",
        "    prioritized_tasks = []\n",
        "    for task_index, task in enumerate(tasks):\n",
        "        win_probs = [calculate_win_probability(emp_idx, task_index) for emp_idx in range(len(employees))]\n",
        "        max_win_prob = max(win_probs)\n",
        "        task_priority = max_win_prob * (1 / (1 + days_until_deadline(task[\"deadline\"])))\n",
        "        prioritized_tasks.append((task[\"name\"], task_priority))\n",
        "\n",
        "    prioritized_tasks.sort(key=lambda x: x[1], reverse=True)\n",
        "    return prioritized_tasks\n",
        "\n",
        "print(\"\\nPrioritized Task List:\")\n",
        "for task_name, priority in prioritize_tasks():\n",
        "    print(f\"Task: {task_name}, Priority Score: {priority:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrqQmkDS9hAn",
        "outputId": "596bf5b1-0de4-4ca1-a964-6db3f06ad67d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prioritized Task List:\n",
            "Task: Task 3, Priority Score: 0.02\n",
            "Task: Task 1, Priority Score: 0.01\n",
            "Task: Task 2, Priority Score: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgjsDi2uxeGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
